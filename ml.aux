\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Introduction}{11}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.1}notation}{11}{section.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Logistic Regression as a neural network}{13}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}definitions}{13}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}cost function}{13}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Gradient Descent}{14}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Model training}{15}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Forward Propagation}{16}{section.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Activation Functions}{16}{subsection.1.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Backward Propagation}{16}{section.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Update parameters}{17}{section.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Summary}{17}{section.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Logistic Regression in Python}{17}{section.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.10}References}{18}{section.1.10}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Neural Networks}{19}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Lingua franca}{19}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Model training}{20}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Parameter initialization}{21}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Xavier initialization}{22}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Forward Propagation}{22}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Backward Propagation}{22}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Summary}{23}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Deep neural networks in Python}{23}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Neural Networks hyperparameters}{25}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.1}training}{25}{subsection.3.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.2}bias-variance trade-off}{26}{subsection.3.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.3}recipes for high-bias, high-variance}{26}{subsection.3.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.4}Regularization (weight decay)}{27}{subsection.3.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.5}Inverted Dropout Regularization}{28}{subsection.3.0.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.6}Input Normalization}{28}{subsection.3.0.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.7}Vanishing/Exploding gradients}{28}{subsection.3.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.0.8}gradient checking}{29}{subsection.3.0.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Optimization}{29}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}stochastic, mini-batch, and batch gradient descent}{30}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Gradient descent with momentum}{30}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}RMSprob}{31}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Adaptive Momentum estimation (Adam)}{31}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Hyperparameters}{32}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Learning rate decay}{32}{section.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Tuning parameters}{32}{section.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}coarse to fine search}{33}{subsection.3.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}panda vs caviar training approaches}{33}{subsection.3.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Batch Normalization}{33}{section.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Covariate Shift}{34}{subsection.3.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.2}Batch normalization as a regularization technique}{34}{subsection.3.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.3}Batch normalization on test sets}{35}{subsection.3.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Multi-class classification}{35}{section.3.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.1}Softmax activation}{35}{subsection.3.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Support Vector Machine (SVM)}{35}{section.3.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.1}Large Margins in linear Decision Boundaries}{38}{subsection.3.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.2}Non-linear Decision Boundaries}{38}{subsection.3.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.3}Gaussian kernel}{38}{subsection.3.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.10}Unsupervised Learning (Introduction)}{39}{section.3.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.1}k-mean algorithm}{39}{subsection.3.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10.2}Principle Component Analysis PCA}{40}{subsection.3.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Structuring machine learning}{43}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Machine learning strategy}{43}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}orthogonality}{43}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Set up your Goal}{44}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Evaluation metric}{44}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Precision vs accuracy}{44}{subsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}F1-score}{45}{subsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Satisfying-Optimizing metric}{45}{subsection.4.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}train/dev/test sets}{45}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}dev/test metric}{46}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Human-level performance}{46}{section.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}human(bayes) error}{46}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Error analysis}{47}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Mislabeled data}{48}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Mismatched training dev/test sets}{48}{section.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}Addressing data mismatch}{49}{subsection.4.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.2}Artificial data synthesis}{49}{subsection.4.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Multiple tasks learning}{50}{section.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}Transfer learning}{50}{subsection.4.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}Multitask learning}{50}{subsection.4.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.9}End-to-End Machine Learning}{50}{section.4.9}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Computer Vision}{51}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Object Detection}{51}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Edge Detection}{52}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Padding}{53}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}striding}{54}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Convolution on RGB channels}{54}{subsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Multiple filters Convolution}{54}{subsection.5.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.6}Example ConvNet}{54}{subsection.5.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.7}Pooling Convolutions}{55}{subsection.5.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.8}Max Pooling}{55}{subsection.5.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.9}Average Pooling}{56}{subsection.5.1.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Examples}{56}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}LeNet-5 Network}{56}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}AlexNet Network}{56}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}VGG-16 Network}{57}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}ResNet (Residual Block)}{58}{subsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Inception}{58}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}$1\times {1}$ Convolutions}{59}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Inception Block}{59}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Inception Branches}{59}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Object Detection}{59}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Localization and Detection}{59}{subsection.5.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}classification with localization}{60}{subsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Landmark detection}{60}{subsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Object Detection}{61}{subsection.5.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.5}Convolutional sliding windows}{61}{subsection.5.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.6}Example:}{61}{subsection.5.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Bounding Box prediction}{62}{section.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}YOLO}{62}{subsection.5.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Jaccard distance, or Intersection over Union IOU function}{62}{subsection.5.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Non-Max Suppression}{63}{subsection.5.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Anchor Boxes}{63}{subsection.5.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.5}Region Proposal R-CNN, Fast R-CNN}{63}{subsection.5.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Face Recognition }{64}{section.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Recognition vs. Verification}{64}{subsection.5.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}One-Shot learning}{64}{subsection.5.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.3}Similarity learning function}{64}{subsection.5.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.4}Siamese Network}{65}{subsection.5.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.5}Triplet Loss}{65}{subsection.5.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.6}Binary Classification}{65}{subsection.5.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Neural Style Transfer}{66}{section.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.1}Generated image descent}{66}{subsection.5.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.2}Content cost}{67}{subsection.5.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.3}Style cost}{67}{subsection.5.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.4}Gram Matrix(style)}{67}{subsection.5.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Recurrent Neural Networks RNN}{69}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{69}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Notation}{69}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}RNN}{70}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}RNN model}{70}{subsection.6.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}uni-directional RNN Forward propagation}{70}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}uni-directional RNN backward propagation through time}{71}{section.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Variations of RNN models}{71}{section.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}many-to-one RNN}{72}{subsection.6.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}One-to-Many RNN}{72}{subsection.6.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.3}Many-to-Many of different input/output length}{74}{subsection.6.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Language Model and sequence generation}{74}{section.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Sampling novel sequences}{75}{section.6.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Vanishing/Exploding gradients}{75}{section.6.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.1}Gated Recurrent Unit (GRU)}{75}{subsection.6.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.2}GRU simplified}{76}{subsection.6.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.3}Long Short Term Memory (LSTM)}{77}{subsection.6.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.4}Back-propagation}{78}{subsection.6.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.5}Bidirectional RNN}{78}{subsection.6.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.10}Deep RNNs}{78}{section.6.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.11}Word Representation}{79}{section.6.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.1}Word Embedding}{79}{subsection.6.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.2}Named Entity recognition}{79}{subsection.6.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.3}Learning word embedding}{80}{subsection.6.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.4}Word2Vec}{80}{subsection.6.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.5}Skip gram}{80}{subsection.6.11.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.6}hierarchical SOFTMAX}{80}{subsection.6.11.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.7}Negative Sampling}{81}{subsection.6.11.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.11.8}GloVe (global vector for word representation)}{82}{subsection.6.11.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.12}Example: Sentiment Classification}{83}{section.6.12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.13}Sequence To Sequence Model}{83}{section.6.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13.1}Beam search}{84}{subsection.6.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13.2}normalization}{84}{subsection.6.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13.3}Error Analysis}{85}{subsection.6.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.13.4}Bleu Score}{85}{subsection.6.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.14}Attention Model}{86}{section.6.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.14.1}Attention}{86}{subsection.6.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Probabilistic Graphical Models (PGM)}{87}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Introduction}{87}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}preliminaries}{88}{subsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}factors}{88}{subsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Bayesian Network Fundamentals}{89}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}constructing dependencies}{89}{subsection.7.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Reasoning Patterns on BN}{90}{section.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Flow of Probabilistic Influence}{91}{section.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.5}d-separation}{91}{section.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}I-map}{92}{subsection.7.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Naive Bayes Model}{92}{section.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.7}Template Model}{93}{section.7.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.1}Distribution over Trajectories}{94}{subsection.7.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.2}Markov chain}{94}{subsection.7.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.3}Dynamic Bayesian Network DBN}{95}{subsection.7.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.4}Hidden Markov Model (HMM)}{95}{subsection.7.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.8}Structured CPD}{95}{section.7.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.1}Tree CPD}{96}{subsection.7.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.2}Multiplexer CPD}{97}{subsection.7.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Natural language processing}{99}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}pre-processing}{99}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Example: positive, negative classifier}{99}{section.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Logistic regression classifier}{100}{section.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Naive Bayes classifier}{101}{section.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.5}cosine similaritis}{103}{section.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5.1}Euclidean distance}{104}{subsection.8.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.6}Principle Component Analysis (PCA)}{104}{section.8.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.7}Machine Translation}{105}{section.8.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.1}Loss function L}{106}{subsection.8.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.2}gradient descent}{107}{subsection.8.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.3}fixed number of iterations}{108}{subsection.8.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.4}k-Nearest neighbors algorithm}{108}{subsection.8.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.5}Searching for the translation embedding}{109}{subsection.8.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.6}LSH and document search}{109}{subsection.8.7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.7}Bag-of-words (BOW) document models}{110}{subsection.8.7.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.8} Choosing the number of planes}{110}{subsection.8.7.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7.9} Getting the hash number for a vector}{111}{subsection.8.7.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.8}Probabilistic model of pronounciation and spelling}{112}{section.8.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.8.1}auto-correction}{112}{subsection.8.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.8.2}Bayesian inference model}{113}{subsection.8.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.8.3}Minimum edit distance}{114}{subsection.8.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.9}Grammar Weighted Automata}{114}{section.8.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.9.1}Markov chain}{114}{subsection.8.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.9.2}Hidden Markov Models HMMs}{115}{subsection.8.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.9.3}Viterbi Algorithm}{116}{subsection.8.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.9.4}Part of Speech tagging (POS)}{117}{subsection.8.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.10}N-grams}{118}{section.8.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.10.1}Smoothing}{118}{subsection.8.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.10.2}Back-off}{118}{subsection.8.10.2}\protected@file@percent }
\citation{xyz2}
\bibstyle{apalike}
\bibdata{bib0}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.10.3}Interpolation}{119}{subsection.8.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Appendices}{121}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Introduction to probabilities}{123}{appendix.a.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}probabilities chain rule}{123}{section.a.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Naive Bayes}{123}{section.a.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Covariance}{125}{appendix.a.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Single Value Decomposition}{127}{appendix.a.C}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Exponentially weighted averages}{129}{appendix.a.D}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {subsection}{\numberline {D.0.1}How to choose the value $\beta $ ?}{129}{subsection.a.D.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {E}smoothing (add-k, and add-one Laplacian)}{131}{appendix.a.E}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {F}Kernels, and Convolution functions}{133}{appendix.a.F}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
